{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeongrnin/Computer-vision/blob/mlp/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ANvvBB2n1M9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C0suv3LoZTB"
      },
      "source": [
        "1. MNIST train, test dataset 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNx3uluwocOu"
      },
      "outputs": [],
      "source": [
        "# \"\": 현재 폴더에 MNIST 있음\n",
        "mnist_train=dset.MNIST(\"\", train=True,transform=transforms.ToTensor(), #train 용으로 쓰겠다.\n",
        "                       target_transform=None, download=True)\n",
        "mnist_test=dset.MNIST(\"\", train=False,transform=transforms.ToTensor(), #test 용으로 쓰겠다.\n",
        "                      target_transform=None, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqUQpX_mpFDU"
      },
      "source": [
        "2. 대략적인 데이터 형태"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNFZnBebpGw3"
      },
      "outputs": [],
      "source": [
        "print (\"mnist_train 길이:\", len(mnist_train))\n",
        "print (\"mnist_test 길이:\", len(mnist_test))\n",
        "\n",
        "# 데이터 하나 형태\n",
        "image, label = mnist_train.__getitem__(0) # 0번째 데이터\n",
        "print (\"image data 형태:\", image.size())\n",
        "print (\"label: \", label)\n",
        "\n",
        "# 그리기\n",
        "img = image.numpy() # image 타입을 numpy 로 변환 (1,28,28)\n",
        "plt.title(\"label: %d\" %label )\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL9A75osp9wK"
      },
      "source": [
        "3. 데이터 로드함수\n",
        "\n",
        "학습시킬 때 batch_size 단위로 끊어서 로드하기 위함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CxV9yFYp_Gv"
      },
      "outputs": [],
      "source": [
        "# hyper parameters\n",
        "batch_size = 1024\n",
        "learning_rate = 0.01 # 0.1, 0.01, 0.001, 0.0001, ...\n",
        "num_epoch = 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arXudocEqTvC"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist_train,\n",
        "                                           batch_size=batch_size, # mnist_train 를 트레인 시키자.\n",
        "                                           shuffle=True, num_workers=2,\n",
        "                                           drop_last=True) # batch_size 만큼 나눌 때 나머지는 버려라.\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=2,\n",
        "                                          drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-clI4fwqyUp"
      },
      "outputs": [],
      "source": [
        "n = 3 # 샘플로 그려볼 데이터 개수\n",
        "for i, [imgs, labels] in enumerate(test_loader): # batch_size 만큼\n",
        "  if i>5:\n",
        "    break\n",
        "\n",
        "  print (\"[%d]\" %i)\n",
        "  print (\"한 번에 로드되는 데이터 크기:\", len(imgs))\n",
        "\n",
        "  # 그리기\n",
        "  for j in range(n):\n",
        "    img = imgs[j].numpy() # image 타입을 numpy 로 변환 (1,28,28)\n",
        "    img = img.reshape((img.shape[1], img.shape[2])) # (1,28,28) -> (28,28)\n",
        "    #print img.shape\n",
        "\n",
        "    plt.subplot(1, n, j+1) # (1,3) 형태 플랏의 j 번째 자리에 그리겠다\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(\"label: %d\" %labels[j])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWHSgDnzr1ol"
      },
      "source": [
        "4. 모델 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv6lLVhZr3A8"
      },
      "outputs": [],
      "source": [
        "# 모델 선언\n",
        "# * 퍼셉트론(2 hidden layer) *\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(28*28,256),\n",
        "    nn.Sigmoid(), #nn.ReLU(), # nn.Sigmoid() 91.89%\n",
        "    nn.Linear(256,128),\n",
        "    nn.Linear(128,10),\n",
        ")\n",
        "# 파라미터 보기\n",
        "print(list(model.parameters())) # 초기 파라미터 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgVYNwr1sTzV"
      },
      "outputs": [],
      "source": [
        "#model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97SYkj1l2hgs"
      },
      "outputs": [],
      "source": [
        "def ComputeAccr(dloader, imodel):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for j, [imgs, labels] in enumerate(dloader): # batch_size 만큼\n",
        "    img = imgs # x\n",
        "    label = Variable(labels) # y\n",
        "    #label = Variable(labels),cuda()\n",
        "    # .cuda() : GPU 에 로드되기 위함. 만약 CPU로 설정되어 있다면 에러남\n",
        "\n",
        "    # (batch_size, 1, 28, 28) -> (batch_size, 28, 28)\n",
        "    img = img.reshape((img.shape[0], img.shape[2], img.shape[3]))\n",
        "    # (batch_size, 28, 28) -> (batch_size, 28*28)\n",
        "    img = img.reshape((img.shape[0], img.shape[1]*img.shape[2]))\n",
        "    img = Variable(img, requires_grad=False)\n",
        "    #img = Variable(img, requires_grad=False).cuda()\n",
        "\n",
        "    output = imodel(img) # forward prop.\n",
        "    _, output_index = torch.max(output, 1)\n",
        "\n",
        "    total += label.size(0)\n",
        "    correct += (output_index == label).sum().float()\n",
        "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj4MuHIP3h8V"
      },
      "outputs": [],
      "source": [
        "ComputeAccr(test_loader, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWG3bwcX3m1J"
      },
      "source": [
        "5. loss, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnBS06kN3o0D"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.CrossEntropyLoss() # login(# of classes), target(1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0L-REbu31DD"
      },
      "source": [
        "6. 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bbvlHik32FP",
        "outputId": "fabea3f0-24ef-49de-e8fb-a8273db86580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0..\n",
            "Accuracy of Test Data: 11.295573234558105\n",
            "tensor(2.2943, grad_fn=<NllLossBackward0>)\n",
            "50..\n",
            "Accuracy of Test Data: 80.68576049804688\n",
            "tensor(0.7253, grad_fn=<NllLossBackward0>)\n",
            "100..\n",
            "Accuracy of Test Data: 88.56336975097656\n",
            "tensor(0.4340, grad_fn=<NllLossBackward0>)\n",
            "150..\n",
            "Accuracy of Test Data: 90.10416412353516\n",
            "tensor(0.3652, grad_fn=<NllLossBackward0>)\n",
            "200..\n",
            "Accuracy of Test Data: 90.72265625\n",
            "tensor(0.3520, grad_fn=<NllLossBackward0>)\n",
            "250..\n",
            "Accuracy of Test Data: 91.34114837646484\n",
            "tensor(0.3094, grad_fn=<NllLossBackward0>)\n",
            "300..\n",
            "Accuracy of Test Data: 91.64496612548828\n",
            "tensor(0.2865, grad_fn=<NllLossBackward0>)\n",
            "350..\n",
            "Accuracy of Test Data: 91.88368225097656\n",
            "tensor(0.2912, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "num_epoch = 400\n",
        "for i in range(num_epoch):\n",
        "  for j, [imgs, labels] in enumerate(train_loader): # batch_size 만큼\n",
        "    img = imgs # (batch_size, 1, 28, 28)\n",
        "    label = Variable(labels) # (batch_size)\n",
        "    #label = Variable(labels).cuda() # (batch_size)\n",
        "\n",
        "    # (batch_size, 1, 28, 28) -> (batch_size, 28, 28)\n",
        "    img = img.reshape((img.shape[0], img.shape[2], img.shape[3]))\n",
        "    # (batch_size, 28, 28) -> (batch_size, 28*28)\n",
        "    img = img.reshape((img.shape[0], img.shape[1]*img.shape[2]))\n",
        "    img = Variable(img, requires_grad=True)\n",
        "    #img = Variable(img, requires_grad=True).cuda()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(img) # forward prop.\n",
        "    loss = loss_func(output, label) # logit(# of classes), target(1)\n",
        "\n",
        "    loss.backward() # back prop.\n",
        "    optimizer.step() # weight 조정\n",
        "\n",
        "  if i%50==0:\n",
        "    print(\"%d..\" %i)\n",
        "    ComputeAccr(test_loader, model)\n",
        "    print (loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv6rjFJW6fgF"
      },
      "source": [
        "7. 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fieb5wCy6itq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe75ab15-6aa2-48bc-e96a-a563340b291b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Test Data: 92.08984375\n"
          ]
        }
      ],
      "source": [
        "ComputeAccr(test_loader, model) # 96. %(ReLU), 92.48%(ReLU X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSqg8AEe6ura"
      },
      "source": [
        "8. 학습된 파라미터 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCZOofmw6wrZ"
      },
      "outputs": [],
      "source": [
        "netname = './nets/mlp_weight.pkl'\n",
        "torch.save(model, netname, )\n",
        "\n",
        "#model = torch.load(netname)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVxlHNNG/TprLK6iUF+l7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}